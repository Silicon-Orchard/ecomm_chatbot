{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akibs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akibs\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from nltk import word_tokenize\n",
    "from nltk import StanfordTagger\n",
    "nltk.download('punkt')\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def get_product(text):\n",
    "    keys = []\n",
    "    tokens = word_tokenize(text)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    print(tags)\n",
    "    parsed_text = nlp(u\"{}\".format(text))\n",
    "    \n",
    "    subject = \"\"\n",
    "    for tag in tags:\n",
    "        if tag[1] == \"NN\" or tag[1] == \"NNS\":\n",
    "            keys.append(tag[0])\n",
    "    \n",
    "    for text in parsed_text:\n",
    "        if text.dep_ == \"nsubj\":\n",
    "            subject = text.orth_\n",
    "    if subject:\n",
    "        keys.remove(subject)\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start talking with the bot (type quit to stop)!\n",
      "You:  hello there\n",
      "[('hello', 'NN'), ('there', 'EX')]\n",
      "Found Keys:  ['hello']\n"
     ]
    }
   ],
   "source": [
    "def chat():\n",
    "    print(\"Start talking with the bot (type quit to stop)!\")\n",
    "    while True:\n",
    "        inp = input(\"You: \").lower()\n",
    "        if inp.lower() == \"quit\":\n",
    "            break\n",
    "        elif inp:\n",
    "            print(\"You: \", inp)\n",
    "            print(\"Found Keys: \", get_product(inp))\n",
    "            \n",
    "chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'sku', 'upc', 'ean', 'jan', 'isbn', 'mpn', 'image', 'brand_id',\n",
       "       'supplier_id', 'price', 'cost', 'stock', 'sold', 'minimum',\n",
       "       'weight_class', 'weight', 'length_class', 'length', 'width', 'height',\n",
       "       'kind', 'property', 'tax_id', 'status', 'sort', 'view', 'alias',\n",
       "       'category_store_id', 'store_id', 'date_lastview', 'date_available',\n",
       "       'created_at', 'updated_at', 'namebn', 'keysbn', 'nameen', 'keysen'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"DB\\\\db.csv\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         ['Miniket', 'Rice', 'Premium']\n",
       "1        ['Miniket', 'Rice', 'Standard']\n",
       "2      ['Aromatic', 'chinigura', 'rice']\n",
       "3      ['Aromatic', 'chinigura', 'rice']\n",
       "4        ['Chashi', 'chinigura', 'rice']\n",
       "                     ...                \n",
       "468           ['Pepsi', 'Pet', 'Bottle']\n",
       "469           ['Pepsi', 'Pet', 'Bottle']\n",
       "470           ['Pepsi', 'Pet', 'Bottle']\n",
       "471             ['Pepsi', 'Diet', 'Can']\n",
       "472                     ['Pepsi', 'Can']\n",
       "Name: keysen, Length: 473, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['keysen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "\n",
    "flatten_list = [j for sub in search for j in sub]\n",
    "keys = list(set(flatten_list))\n",
    "keys = [key.lower() for key in keys]\n",
    "\n",
    "def spell_check(keys, word):\n",
    "    return difflib.get_close_matches(word, keys, 1, 0.5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You typed: minicate - Did you mean: miniket\n",
      "You typed: primium - Did you mean: premium\n",
      "You typed: chinygora - Did you mean: chinigura\n"
     ]
    }
   ],
   "source": [
    "inp = \"\"\n",
    "while True:\n",
    "    inp = input(\"Enter word: \")\n",
    "    if inp == \"quit\":\n",
    "        break \n",
    "    print(\"You typed: {} - Did you mean: {}\".format(inp, spell_check(keys, inp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You searched for \"premium rice\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "keys = \"premium Rice\".lower().split()\n",
    "\n",
    "print(\"You searched for \\\"{}\\\"\".format(\" \".join(keys)))\n",
    "def searchdb(keys, search):\n",
    "    scores = np.zeros(len(search))\n",
    "    for key in keys:\n",
    "        for i, s in enumerate(search):\n",
    "            if key in s:\n",
    "                scores[i] += 1\n",
    "    \n",
    "    results = np.argpartition(scores, -(np.count_nonzero(scores==max(scores))))[-(np.count_nonzero(scores==max(scores))):]\n",
    "    print(\"Possible Results: \")\n",
    "    print([\" \".join(search[i]) for i in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible Results: \n",
      "['teer chinigura rice', 'teer chinigura rice', 'chashi chinigura rice', 'fresh chinigura rice', 'chashi chinigura rice', 'aromatic chinigura rice', 'aromatic chinigura rice', 'fresh chinigura rice', 'miniket rice standard', 'rupchanda premium chinigura rice', 'rupchanda premium chinigura rice', 'pran chinigura rice', 'pran chinigura rice', 'aci premium chinigura rice', 'aci premium chinigura rice', 'dove detox ritul with matcha & rice milk shampoo ', 'dove with pink lotus& rice water shampoo ', 'miniket rice premium']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "words = [\"buy\",\"verb\",\"obtain\",\"purchase\",\"acquire\",\"obtain\",\"get\",\"pick\",\"snap\",\"take\",\"secure\",\"procure\",\"score\",\"have\"]\n",
    "text = \"I want to buy 1kg rice\"\n",
    "for word in words:\n",
    "    if word in text:\n",
    "        text = text[text.find(word):].replace(word, \"\")\n",
    "        break\n",
    "print(searchdb([text.split()[1]]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1', 'CD'), ('black', 'JJ'), ('pant', 'NN')]\n",
      "[('full', 'JJ'), ('sleeve', 'NN'), ('shirt', 'NN')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sleeve', 'shirt']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '1 black pant and full sleeve shirt'\n",
    "if 'and' in text:\n",
    "    text = text.split('and')\n",
    "get_product(text[0])\n",
    "get_product(text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('i', 'NN'), ('want', 'VBP'), ('a', 'DT'), ('black', 'JJ')]\n",
      "[('white', 'JJ'), ('shirt', 'NN')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['shirt']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'i want a black and white shirt'\n",
    "if 'and' in text:\n",
    "    text = text.split('and')\n",
    "get_product(text[0])\n",
    "get_product(text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_class=   {   \n",
    "                    'kg': ['kg','kilogram', 'killogram', 'kiloggram', 'killoggram'], \n",
    "                    'gm': ['gm','gram', 'grram', 'gramm'], \n",
    "                    'ml': ['ml','mililiter', 'mililitter', 'milliliter', 'millilitter'], \n",
    "                    'ltr': ['ltr','liter', 'lt', 'litter']\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7up'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"500 ml 7up\"\n",
    "import re\n",
    "text.replace(re.search('^\\d+ *\\w+ ', text.strip()).group(0), \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "71190c2adcefb3fdd9f3684881c64f9e247f26e61163d04fffe1cacfb0960359"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
